{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import iris\n",
    "from scipy.spatial import KDTree\n",
    "import iris.quickplot as qplt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import numpy as np\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import iris.coord_categorisation\n",
    "from mpl_toolkits.axes_grid1.inset_locator import InsetPosition\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.cm as cm\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_region(cube,lon_west,lon_east,lat_south,lat_north):\n",
    "    cube_region_tmp = cube.intersection(longitude=(lon_west, lon_east))\n",
    "    cube_region = cube_region_tmp.intersection(latitude=(lat_south, lat_north))\n",
    "    return cube_region\n",
    "\n",
    "\n",
    "def area_avg(cube):\n",
    "    try:\n",
    "        cube.coord('latitude').guess_bounds()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        cube.coord('longitude').guess_bounds()\n",
    "    except:\n",
    "        pass\n",
    "    grid_areas = iris.analysis.cartography.area_weights(cube)\n",
    "    return cube.collapsed(['longitude', 'latitude'], iris.analysis.MEAN, weights=grid_areas)\n",
    "\n",
    "def extract_lat_lon(cube,my_lat,my_lon):\n",
    "    lat = cube.coord('latitude')\n",
    "    lon = cube.coord('longitude')\n",
    "    lat_coord1 = lat.nearest_neighbour_index(my_lat)\n",
    "    lon_coord1 = lon.nearest_neighbour_index(my_lon)\n",
    "    return cube.data[:,lat_coord1,lon_coord1].data\n",
    "\n",
    "\n",
    "def extract_lat_lon_cube(cube,my_lat,my_lon):\n",
    "    lat = cube.coord('latitude')\n",
    "    lon = cube.coord('longitude')\n",
    "    lat_coord1 = lat.nearest_neighbour_index(my_lat)\n",
    "    lon_coord1 = lon.nearest_neighbour_index(my_lon)\n",
    "    return cube[:,lat_coord1,lon_coord1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/ph290/Downloads/era5_GBR/era5_GBR_surfacetemperature.nc'\n",
    "file_bottom = '/Users/ph290/Downloads/era5_GBR/era5_GBR_bottomtemperature.nc'\n",
    "\n",
    "# cube = iris.load_cube(file)[0]\n",
    "\n",
    "cube_all_bottom = iris.load_cube(file_bottom)\n",
    "cube_all = iris.load_cube(file)\n",
    "try:\n",
    "    iris.coord_categorisation.add_year(cube_all, 'time', name='year')\n",
    "    iris.coord_categorisation.add_month(cube_all, 'time', name='month')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    iris.coord_categorisation.add_year(cube_all_bottom, 'time', name='year')\n",
    "    iris.coord_categorisation.add_month(cube_all_bottom, 'time', name='month')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# cube_all = cube_all.aggregated_by('year', iris.analysis.MEAN)\n",
    "\n",
    "\n",
    "# cube_all.coord('longitude').points = cube_all.coord('longitude').points+180\n",
    "# cube_all.data = np.ma.masked_array(cube_all.data)\n",
    "# cube_all.data.fill_value = 9.96920997e+36\n",
    "cube_all.data = np.ma.masked_where(cube_all.data == 9.96920997e+36, cube_all.data)\n",
    "cube_all_bottom.data = np.ma.masked_where(cube_all_bottom.data == 9.96920997e+36, cube_all_bottom.data)\n",
    "\n",
    "a = cube_all[0,:,:].data.copy()\n",
    "a = np.ma.masked_where(np.logical_not(np.isfinite(a)),a)\n",
    "x,y=np.meshgrid(cube_all.coord('longitude').points,cube_all.coord('latitude').points)\n",
    "xygood = np.array((x[~a.mask],y[~a.mask])).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://portal.aodn.org.au/search\n",
    "\n",
    "# obs_file = 'NRSNSI.csv.gz'\n",
    "# obs_file = 'GBRLSH.csv.gz'\n",
    "# obs_file = 'GBRPPS.csv.gz'\n",
    "# obs_file = 'NRSYON.csv.gz'\n",
    "# obs_file = 'GBRHIS.csv.gz'\n",
    "# df = pd.read_csv('data/'+obs_file, compression='gzip',header=21)\n",
    "\n",
    "\n",
    "obs_file = 'IMOS_FAIMMS.csv.gz'\n",
    "df = pd.read_csv('data/'+obs_file, compression='gzip',header=39)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.loc[df.NOMINAL_DEPTH < 2.0]\n",
    "\n",
    "site_codes = np.unique(df2.site_code)\n",
    "# 7,8,12,13,14,16,17,18,21,22,23,24\n",
    "site_code = site_codes[24]\n",
    "df_surf = df2.loc[(df2.site_code == site_code) & (df.VALUES_quality_control == 1)]\n",
    "lat = df_surf.LATITUDE.mean()\n",
    "lon = df_surf.LONGITUDE.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "min_lon = np.min(cube_all.coord('longitude').points)\n",
    "max_lon = np.max(cube_all.coord('longitude').points)\n",
    "min_lat = np.min(cube_all.coord('latitude').points)\n",
    "max_lat = np.max(cube_all.coord('latitude').points)\n",
    "\n",
    "# if (lon >= min_lon) & (lon <= max_lon) & (lat >= min_lat) & (lat <= max_lat):\n",
    "#     fig= plt.subplots(figsize=(10, 10))\n",
    "#     #plot map of the mooring location\n",
    "#     qplt.pcolormesh(cube_all[0])\n",
    "#     plt.scatter(lon,lat)\n",
    "#     plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_values=np.array([])\n",
    "obs_latitude=np.array([])\n",
    "obs_month=np.array([])\n",
    "model_values=np.array([])\n",
    "\n",
    "\n",
    "site_codes = np.unique(df2.site_code)\n",
    "# 7,8,12,13,14,16,17,18,21,22,23,24\n",
    "for site_code in site_codes:\n",
    "    df_surf = df2.loc[(df.site_code == site_code) & (df2.VALUES_quality_control == 1)]\n",
    "    # note a a QC flag pv  2 will define that the ARGO quality control procedure was used for the dataset. QC of 1 hade some spruriously low values\n",
    "    lat = df_surf.LATITUDE.mean()\n",
    "    lon = df_surf.LONGITUDE.mean()\n",
    "\n",
    "#     fig= plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    if np.isfinite(KDTree(xygood).query([lon,lat])[0]):\n",
    "        index = KDTree(xygood).query([lon,lat])[1]\n",
    "    #     xygood[index][0]\n",
    "        model_ts = extract_lat_lon(cube_all,xygood[index][1],xygood[index][0])\n",
    "        time = cube_all.coord('time')\n",
    "        times = time.units.num2date(time.points)\n",
    "        where_good_data = np.where(model_ts < 1000.0)\n",
    "\n",
    "        if (lon >= min_lon) & (lon <= max_lon) & (lat >= min_lat) & (lat <= max_lat):\n",
    "            try:\n",
    "        #         df_surf['old_TIME'] = df_surf.TIME\n",
    "                df_surf['TIME_datetime'] = pd.to_datetime(df_surf.TIME,format='%Y-%m-%dT%H:%M:%SZ')\n",
    "                df_surf = df_surf.set_index('TIME_datetime',drop=False)\n",
    "            except:\n",
    "                pass\n",
    "            df_surf['month'] = df_surf.TIME_datetime.dt.month\n",
    "            df_surf = df_surf.groupby(pd.Grouper(freq='1D')).mean()\n",
    "\n",
    "            basedate = pd.Timestamp('1970-01-01')\n",
    "\n",
    "            model_dates = times[where_good_data]\n",
    "            model_days_since_bas = ( pd.to_datetime(model_dates)- basedate).days.values\n",
    "            model_data = model_ts[where_good_data]\n",
    "            \n",
    "            obs_days_since_bas = (df_surf.index- basedate).days.values\n",
    "#             finite_obs_data_loc = np.where(np.isfinite(df_surf.VALUES.values))\n",
    "#             obs_days_since_bas = obs_days_since_bas[finite_obs_data_loc]\n",
    "            loc_where_obs_days_within_model_days =  np.where((obs_days_since_bas <= np.max(model_days_since_bas)) & (np.isfinite(df_surf.VALUES.values)) & (df_surf.VALUES.values >17.0 ))[0]\n",
    "            obs_days_since_bas = obs_days_since_bas[loc_where_obs_days_within_model_days]\n",
    "#             finite_obs_data_loc = np.where(np.isfinite(df_surf.VALUES.values))\n",
    "\n",
    "            interp_function = interp1d(model_days_since_bas, model_data)\n",
    "\n",
    "            # plt.scatter(obs_days_since_bas,df_surf.VALUES.values[finite_obs_data_loc],color='r',alpha=0.5)\n",
    "#             plt.scatter(obs_days_since_bas, interp_function(obs_days_since_bas), color='b',alpha=0.1)\n",
    "            obs_values = np.append(obs_values, df_surf.VALUES.values[loc_where_obs_days_within_model_days])\n",
    "            model_values = np.append(model_values, interp_function(obs_days_since_bas))\n",
    "            obs_latitude = np.append(obs_latitude,df_surf.LATITUDE.values[loc_where_obs_days_within_model_days])\n",
    "            obs_month = np.append(obs_month,df_surf.month.values[loc_where_obs_days_within_model_days])\n",
    "#             plt.scatter(df_surf.VALUES.values[loc_where_obs_days_within_model_days],interp_function(obs_days_since_bas))\n",
    "\n",
    "    #     if (lon >= min_lon) & (lon <= max_lon) & (lat >= min_lat) & (lat <= max_lat):\n",
    "    #         plt.plot(times[where_good_data],model_ts[where_good_data])\n",
    "    #         try:\n",
    "    #     #         df_surf['old_TIME'] = df_surf.TIME\n",
    "    #             df_surf['TIME_datetime'] = pd.to_datetime(df_surf.TIME,format='%Y-%m-%dT%H:%M:%SZ')\n",
    "    #             df_surf['year'] = df_surf.TIME_datetime.dt.year\n",
    "    #             df_surf['month'] = df_surf.TIME_datetime.dt.month\n",
    "    #             df_surf['day'] = df_surf.TIME_datetime.dt.day\n",
    "    #             df_surf = df_surf.set_index('TIME_datetime',drop=False)\n",
    "    #         except:\n",
    "    #             pass\n",
    "\n",
    "    #         df_surf = df_surf.groupby(pd.Grouper(freq='1D')).mean()\n",
    "    #         plt.scatter(df_surf.index.values,df_surf.VALUES.values,color='r')\n",
    "    #         plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm\n",
    "import matplotlib.colors\n",
    "\n",
    "cyclic_viridis = matplotlib.colors.LinearSegmentedColormap.from_list(\n",
    "    'cyclic_viridis',\n",
    "    [(0, matplotlib.cm.viridis.colors[0]),\n",
    "     (0.25, matplotlib.cm.viridis.colors[256 // 3]),\n",
    "     (0.5, matplotlib.cm.viridis.colors[2 * 256 // 3]),\n",
    "     (0.75, matplotlib.cm.viridis.colors[-1]),\n",
    "     (1.0, matplotlib.cm.viridis.colors[0])])\n",
    "\n",
    "x,y=obs_values,model_values\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(15,6))\n",
    "# ax.scatter(x, y, c=z, s=10, edgecolor='', cmap=cm.plasma)\n",
    "# c = ax.scatter(x, y, c=obs_latitude, s=20, edgecolor='',alpha=0.25, cmap=cm.viridis)\n",
    "c = ax1.scatter(x, y, c=obs_month, s=2.5, edgecolor='',alpha=0.7, cmap=cyclic_viridis)\n",
    "ax1.set_ylim([15,35])\n",
    "ax1.set_xlim([15,35])\n",
    "ax1.set_xlabel('Observed temperature')\n",
    "ax1.set_ylabel('Modelled temperature')\n",
    "ax1.plot([0,40],[0,40],'k')\n",
    "cbar1 = plt.colorbar(c,ax=ax1)\n",
    "cbar1.set_label('month of year')\n",
    "\n",
    "\n",
    "c2 = ax2.scatter(x, y, c=obs_latitude, s=2.5, edgecolor='',alpha=0.7, cmap=cm.viridis)\n",
    "ax2.set_ylim([15,35])\n",
    "ax2.set_xlim([15,35])\n",
    "ax2.set_xlabel('Observed temperature')\n",
    "ax2.set_ylabel('Modelled temperature')\n",
    "ax2.plot([0,40],[0,40],'k')\n",
    "cbar2 = plt.colorbar(c2,ax=ax2)\n",
    "cbar2.set_label('latitude ($^o$N)')\n",
    "\n",
    "\n",
    "# plt.xticks(fontsize=12)\n",
    "# plt.yticks(fontsize=12)\n",
    "\n",
    "\n",
    "plt.savefig('/Users/ph290/Documents/HalloranSync/documents/papers_in_prep/s2p3v2/figures/GBR_sst_validation_IMOS_FAIMMS.pdf')\n",
    "plt.savefig('/Users/ph290/Documents/HalloranSync/documents/papers_in_prep/s2p3v2/figures/GBR_sst_validationIMOS_FAIMMS.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bottom temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# obs_file = 'NRSNSI.csv.gz' # 63m\n",
    "# obs_file = 'GBRLSH.csv.gz' # 31m\n",
    "# obs_file = 'GBRPPS.csv.gz' # 68m\n",
    "# obs_file = 'NRSYON.csv.gz' # 27m\n",
    "# obs_file = 'GBRHIS.csv.gz' # 43m\n",
    "# obs_file = 'GBROTE.csv.gz' #59.3m\n",
    "# df_bottom = pd.read_csv('data/'+obs_file, compression='gzip',header=21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = ['NRSNSI','GBRLSH','NRSYON','GBRHIS']\n",
    "depths =[63,31,27,43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "obs_values_bottom=np.array([])\n",
    "obs_latitude_bottom=np.array([])\n",
    "obs_month_bottom=np.array([])\n",
    "model_values_bottom=np.array([])\n",
    "\n",
    "for i,dummy in enumerate(sites):\n",
    "    df_bottom = pd.read_csv('data/'+sites[i]+'.csv.gz', compression='gzip',header=21)\n",
    "\n",
    "    df_bottom_tmp = df_bottom.loc[df_bottom.DEPTH > depths[i]-5.0]\n",
    "#     df_bottom_tmp = df_bottom.loc[df_bottom.DEPTH > depths[i]-2.0]\n",
    "\n",
    "    try:\n",
    "        lat = df_bottom_tmp.LATITUDE.mean()\n",
    "    except:\n",
    "        lat = df_bottom_tmp.LATITUDE.iloc[0]\n",
    "\n",
    "    try:\n",
    "        lon = df_bottom_tmp.LONGITUDE.mean()\n",
    "    except:\n",
    "        lon = df_bottom_tmp.LONGITUDE.iloc[0]\n",
    "        \n",
    "    #     fig= plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    if np.isfinite(KDTree(xygood).query([lon,lat])[0]):\n",
    "        index = KDTree(xygood).query([lon,lat])[1]\n",
    "    #     xygood[index][0]\n",
    "        model_ts = extract_lat_lon(cube_all_bottom,xygood[index][1],xygood[index][0])\n",
    "        time = cube_all.coord('time')\n",
    "        times = time.units.num2date(time.points)\n",
    "        where_good_data = np.where(model_ts < 1000.0)\n",
    "\n",
    "        if (lon >= min_lon) & (lon <= max_lon) & (lat >= min_lat) & (lat <= max_lat):\n",
    "            try:\n",
    "        #         df_surf['old_TIME'] = df_surf.TIME\n",
    "                df_bottom_tmp['TIME_datetime'] = pd.to_datetime(df_bottom_tmp.TIME,format='%Y-%m-%dT%H:%M:%SZ')\n",
    "                df_bottom_tmp = df_bottom_tmp.set_index('TIME_datetime',drop=False)\n",
    "            except:\n",
    "                pass\n",
    "            df_bottom_tmp['month'] = df_bottom_tmp.TIME_datetime.dt.month\n",
    "            df_bottom_tmp = df_bottom_tmp.groupby(pd.Grouper(freq='1D')).mean()\n",
    "\n",
    "            basedate = pd.Timestamp('1970-01-01')\n",
    "\n",
    "            model_dates = times[where_good_data]\n",
    "            model_days_since_bas = ( pd.to_datetime(model_dates)- basedate).days.values\n",
    "            model_data = model_ts[where_good_data]\n",
    "\n",
    "            obs_days_since_bas = (df_bottom_tmp.index- basedate).days.values\n",
    "    #             finite_obs_data_loc = np.where(np.isfinite(df_surf.VALUES.values))\n",
    "    #             obs_days_since_bas = obs_days_since_bas[finite_obs_data_loc]\n",
    "            loc_where_obs_days_within_model_days =  np.where((obs_days_since_bas <= np.max(model_days_since_bas)) & (np.isfinite(df_bottom_tmp.TEMP.values)))[0]\n",
    "            obs_days_since_bas = obs_days_since_bas[loc_where_obs_days_within_model_days]\n",
    "    #             finite_obs_data_loc = np.where(np.isfinite(df_surf.VALUES.values))\n",
    "\n",
    "            interp_function = interp1d(model_days_since_bas, model_data)\n",
    "\n",
    "            # plt.scatter(obs_days_since_bas,df_surf.VALUES.values[finite_obs_data_loc],color='r',alpha=0.5)\n",
    "    #             plt.scatter(obs_days_since_bas, interp_function(obs_days_since_bas), color='b',alpha=0.1)\n",
    "            obs_values_bottom = np.append(obs_values_bottom, df_bottom_tmp.TEMP.values[loc_where_obs_days_within_model_days])\n",
    "            model_values_bottom = np.append(model_values_bottom, interp_function(obs_days_since_bas))\n",
    "            obs_latitude_bottom = np.append(obs_latitude_bottom,df_bottom_tmp.LATITUDE.values[loc_where_obs_days_within_model_days])\n",
    "            obs_month_bottom = np.append(obs_month_bottom,df_bottom_tmp.month.values[loc_where_obs_days_within_model_days])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm\n",
    "import matplotlib.colors\n",
    "\n",
    "cyclic_viridis = matplotlib.colors.LinearSegmentedColormap.from_list(\n",
    "    'cyclic_viridis',\n",
    "    [(0, matplotlib.cm.viridis.colors[0]),\n",
    "     (0.25, matplotlib.cm.viridis.colors[256 // 3]),\n",
    "     (0.5, matplotlib.cm.viridis.colors[2 * 256 // 3]),\n",
    "     (0.75, matplotlib.cm.viridis.colors[-1]),\n",
    "     (1.0, matplotlib.cm.viridis.colors[0])])\n",
    "\n",
    "x,y=obs_values_bottom,model_values_bottom\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(15,6))\n",
    "# ax.scatter(x, y, c=z, s=10, edgecolor='', cmap=cm.plasma)\n",
    "# c = ax.scatter(x, y, c=obs_latitude_bottom, s=20, edgecolor='',alpha=0.25, cmap=cm.viridis)\n",
    "c = ax1.scatter(x, y, c=obs_month_bottom, s=10, edgecolor='',alpha=0.7, cmap=cyclic_viridis)\n",
    "ax1.set_ylim([15,35])\n",
    "ax1.set_xlim([15,35])\n",
    "ax1.set_xlabel('Observed temperature')\n",
    "ax1.set_ylabel('Modelled temperature')\n",
    "ax1.plot([0,40],[0,40],'k')\n",
    "cbar1 = plt.colorbar(c,ax=ax1)\n",
    "cbar1.set_label('month of year')\n",
    "\n",
    "\n",
    "c2 = ax2.scatter(x, y, c=obs_latitude_bottom, s=10, edgecolor='',alpha=0.7, cmap=cm.viridis)\n",
    "ax2.set_ylim([15,35])\n",
    "ax2.set_xlim([15,35])\n",
    "ax2.set_xlabel('Observed temperature')\n",
    "ax2.set_ylabel('Modelled temperature')\n",
    "ax2.plot([0,40],[0,40],'k')\n",
    "cbar2 = plt.colorbar(c2,ax=ax2)\n",
    "cbar2.set_label('latitude ($^o$N)')\n",
    "\n",
    "\n",
    "# plt.xticks(fontsize=12)\n",
    "# plt.yticks(fontsize=12)\n",
    "\n",
    "\n",
    "plt.savefig('/Users/ph290/Documents/HalloranSync/documents/papers_in_prep/s2p3v2/figures/GBR_bottom_t_validation_IMOS_FAIMMS.pdf')\n",
    "plt.savefig('/Users/ph290/Documents/HalloranSync/documents/papers_in_prep/s2p3v2/figures/GBR_bottom_t_validationIMOS_FAIMMS.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surface and bottom together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm\n",
    "import matplotlib.colors\n",
    "\n",
    "def get_axis_limits(ax, xscale=.45, yscale=.95):\n",
    "    return ax.get_xlim()[1]*xscale, ax.get_ylim()[1]*yscale\n",
    "\n",
    "\n",
    "cyclic_viridis = matplotlib.colors.LinearSegmentedColormap.from_list(\n",
    "    'cyclic_viridis',\n",
    "    [(0, matplotlib.cm.viridis.colors[0]),\n",
    "     (0.25, matplotlib.cm.viridis.colors[256 // 3]),\n",
    "     (0.5, matplotlib.cm.viridis.colors[2 * 256 // 3]),\n",
    "     (0.75, matplotlib.cm.viridis.colors[-1]),\n",
    "     (1.0, matplotlib.cm.viridis.colors[0])])\n",
    "\n",
    "### surface\n",
    "\n",
    "x,y=obs_values,model_values\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2,figsize=(15,13))\n",
    "# ax.scatter(x, y, c=z, s=10, edgecolor='', cmap=cm.plasma)\n",
    "# c = ax.scatter(x, y, c=obs_latitude, s=20, edgecolor='',alpha=0.25, cmap=cm.viridis)\n",
    "c = ax1.scatter(x, y, c=obs_month, s=2.5, edgecolor='',alpha=0.7, cmap=cyclic_viridis)\n",
    "ax1.set_ylim([15,35])\n",
    "ax1.set_xlim([15,35])\n",
    "ax1.set_xlabel('Observed surface temperature')\n",
    "ax1.set_ylabel('Modelled surface temperature')\n",
    "ax1.plot([0,40],[0,40],'k')\n",
    "cbar1 = plt.colorbar(c,ax=ax1)\n",
    "cbar1.set_label('month of year')\n",
    "\n",
    "\n",
    "c2 = ax2.scatter(x, y, c=obs_latitude, s=2.5, edgecolor='',alpha=0.7, cmap=cm.viridis)\n",
    "ax2.set_ylim([15,35])\n",
    "ax2.set_xlim([15,35])\n",
    "ax2.set_xlabel('Observed surface temperature')\n",
    "ax2.set_ylabel('Modelled surface temperature')\n",
    "ax2.plot([0,40],[0,40],'k')\n",
    "cbar2 = plt.colorbar(c2,ax=ax2)\n",
    "cbar2.set_label('latitude ($^o$N)')\n",
    "\n",
    "\n",
    "### bottom\n",
    "\n",
    "x,y=obs_values_bottom,model_values_bottom\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "# ax.scatter(x, y, c=z, s=10, edgecolor='', cmap=cm.plasma)\n",
    "# c = ax.scatter(x, y, c=obs_latitude_bottom, s=20, edgecolor='',alpha=0.25, cmap=cm.viridis)\n",
    "c = ax3.scatter(x, y, c=obs_month_bottom, s=10, edgecolor='',alpha=0.7, cmap=cyclic_viridis)\n",
    "ax3.set_ylim([15,35])\n",
    "ax3.set_xlim([15,35])\n",
    "ax3.set_xlabel('Observed bottom temperature')\n",
    "ax3.set_ylabel('Modelled bottom temperature')\n",
    "ax3.plot([0,40],[0,40],'k')\n",
    "cbar1 = plt.colorbar(c,ax=ax3)\n",
    "cbar1.set_label('month of year')\n",
    "\n",
    "\n",
    "c2 = ax4.scatter(x, y, c=obs_latitude_bottom, s=10, edgecolor='',alpha=0.7, cmap=cm.viridis)\n",
    "ax4.set_ylim([15,35])\n",
    "ax4.set_xlim([15,35])\n",
    "ax4.set_xlabel('Observed bottom temperature')\n",
    "ax4.set_ylabel('Modelled bottom temperature')\n",
    "ax4.plot([0,40],[0,40],'k')\n",
    "cbar2 = plt.colorbar(c2,ax=ax4)\n",
    "cbar2.set_label('latitude ($^o$N)')\n",
    "\n",
    "ax1.annotate('A', xy=get_axis_limits(ax1))\n",
    "ax2.annotate('B', xy=get_axis_limits(ax2))\n",
    "ax3.annotate('C', xy=get_axis_limits(ax3))\n",
    "ax4.annotate('D', xy=get_axis_limits(ax4))\n",
    "# plt.xticks(fontsize=12)\n",
    "# plt.yticks(fontsize=12)\n",
    "\n",
    "\n",
    "# plt.savefig('/Users/ph290/Documents/HalloranSync/documents/papers_in_prep/s2p3v2/figures/GBR_sst_validation_IMOS_surf_and_bottom.pdf')\n",
    "plt.savefig('/Users/ph290/Documents/HalloranSync/documents/papers_in_prep/s2p3v2/figures/GBR_sst_validationIMOS_surf_and_bottom.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "projection=ccrs.PlateCarree()\n",
    "# ax3 = plt.axes([0, 0, 1, 1], projection=projection)\n",
    "fig = plt.figure(figsize=(5, 6))\n",
    "ax3 = fig.add_subplot(1, 1, 1, projection=projection)\n",
    "ax3.set_extent([135, 160, -40, -5], ccrs.PlateCarree())\n",
    "ax3.coastlines('50m')\n",
    "\n",
    "\n",
    "for i,dummy in enumerate(sites):\n",
    "    df_bottom = pd.read_csv('data/'+sites[i]+'.csv.gz', compression='gzip',header=21)\n",
    "    df_bottom_tmp = df_bottom.loc[df_bottom.DEPTH > depths[i]-5.0]\n",
    "\n",
    "    try:\n",
    "        lat = df_bottom_tmp.LATITUDE.mean()\n",
    "    except:\n",
    "        lat = df_bottom_tmp.LATITUDE.iloc[0]\n",
    "\n",
    "    try:\n",
    "        lon = df_bottom_tmp.LONGITUDE.mean()\n",
    "    except:\n",
    "        lon = df_bottom_tmp.LONGITUDE.iloc[0]\n",
    "        \n",
    "    #     fig= plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    if np.isfinite(KDTree(xygood).query([lon,lat])[0]):\n",
    "        index = KDTree(xygood).query([lon,lat])[1]\n",
    "    #     xygood[index][0]\n",
    "        model_ts = extract_lat_lon(cube_all_bottom,xygood[index][1],xygood[index][0])\n",
    "        time = cube_all.coord('time')\n",
    "        times = time.units.num2date(time.points)\n",
    "        where_good_data = np.where(model_ts < 1000.0)\n",
    "\n",
    "        if (lon >= min_lon) & (lon <= max_lon) & (lat >= min_lat) & (lat <= max_lat):\n",
    "            if i== 0:\n",
    "                ax3.scatter(lon,lat,color='b',s=200,alpha=0.3,label='bottom observations')\n",
    "            else:\n",
    "                ax3.scatter(lon,lat,color='b',s=200,alpha=0.3)\n",
    "\n",
    "\n",
    "site_codes = np.unique(df.site_code)\n",
    "# 7,8,12,13,14,16,17,18,21,22,23,24\n",
    "add_label=True\n",
    "for i,site_code in enumerate(site_codes):\n",
    "    df_surf = df.loc[(df.site_code == site_code) & (df.VALUES_quality_control == 1)]\n",
    "    # note a a QC flag pv  2 will define that the ARGO quality control procedure was used for the dataset. QC of 1 hade some spruriously low values\n",
    "    lat = df_surf.LATITUDE.mean()\n",
    "    lon = df_surf.LONGITUDE.mean()\n",
    "    if (lon >= min_lon) & (lon <= max_lon) & (lat >= min_lat) & (lat <= max_lat):\n",
    "        if add_label:\n",
    "            ax3.scatter(lon,lat,color='r',s=50,alpha=0.5,label='surface observations')\n",
    "            add_label = False\n",
    "        else:\n",
    "            ax3.scatter(lon,lat,color='r',s=50,alpha=0.5)\n",
    "\n",
    "plt.legend()\n",
    "fig.tight_layout(pad=3)\n",
    "plt.savefig('/Users/ph290/Documents/HalloranSync/documents/papers_in_prep/s2p3v2/figures/GBR_sst_validationIMOS_bottom_sites.png',dpi=600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# biology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://portal.aodn.org.au/search\n",
    "\n",
    "obs_file = 'IMOS_Australian_National_Mooring_Network_and_CTD_burst_averaged_data_products.csv.gz'\n",
    "df4 = pd.read_csv('data/'+obs_file, compression='gzip',header=27)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df5 = df4.loc[df4.instrument_nominal_depth < 2.0]\n",
    "df5 = df4.loc[df4.instrument_nominal_depth < 12.0] # neccesary to get a decent no. sites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "site_codes = np.unique(df5.site_code)\n",
    "# 7,8,12,13,14,16,17,18,21,22,23,24\n",
    "site_code = site_codes[0]\n",
    "df_surf5 = df5.loc[(df5.site_code == site_code)]\n",
    "lat = df_surf5.LATITUDE.mean()\n",
    "lon = df_surf5.LONGITUDE.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/ph290/Downloads/era5_GBR/era5_GBR_surfacechlorophyll.nc'\n",
    "\n",
    "cube_all_chl = iris.load_cube(file)\n",
    "try:\n",
    "    iris.coord_categorisation.add_year(cube_all_chl, 'time', name='year')\n",
    "    iris.coord_categorisation.add_month(cube_all_chl, 'time', name='month')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "# cube_all = cube_all.aggregated_by('year', iris.analysis.MEAN)\n",
    "\n",
    "\n",
    "# cube_all.coord('longitude').points = cube_all.coord('longitude').points+180\n",
    "# cube_all.data = np.ma.masked_array(cube_all.data)\n",
    "# cube_all.data.fill_value = 9.96920997e+36\n",
    "cube_all_chl.data = np.ma.masked_where(cube_all_chl.data == 9.96920997e+36, cube_all.data)\n",
    "\n",
    "a = cube_all_chl[0,:,:].data.copy()\n",
    "a = np.ma.masked_where(np.logical_not(np.isfinite(a)),a)\n",
    "x,y=np.meshgrid(cube_all_chl.coord('longitude').points,cube_all_chl.coord('latitude').points)\n",
    "xygood = np.array((x[~a.mask],y[~a.mask])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lon = np.min(cube_all_chl.coord('longitude').points)\n",
    "max_lon = np.max(cube_all_chl.coord('longitude').points)\n",
    "min_lat = np.min(cube_all_chl.coord('latitude').points)\n",
    "max_lat = np.max(cube_all_chl.coord('latitude').points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_values=np.array([])\n",
    "obs_latitude=np.array([])\n",
    "obs_month=np.array([])\n",
    "model_values=np.array([])\n",
    "\n",
    "\n",
    "site_codes = np.unique(df5.site_code)\n",
    "# 7,8,12,13,14,16,17,18,21,22,23,24\n",
    "for site_code in site_codes:\n",
    "# site_code = site_codes[0]\n",
    "    df_surf = df5.loc[(df5.site_code == site_code)]\n",
    "    # note a a QC flag pv  2 will define that the ARGO quality control procedure was used for the dataset. QC of 1 hade some spruriously low values\n",
    "    lat = df_surf.LATITUDE.mean()\n",
    "    lon = df_surf.LONGITUDE.mean()\n",
    "\n",
    "    #     fig= plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    if np.isfinite(KDTree(xygood).query([lon,lat])[0]):\n",
    "        index = KDTree(xygood).query([lon,lat])[1]\n",
    "    #     xygood[index][0]\n",
    "        model_ts_cube = extract_lat_lon_cube(cube_all,xygood[index][1],xygood[index][0])\n",
    "        model_ts = model_ts_cube.data\n",
    "        time = cube_all.coord('time')\n",
    "        times = time.units.num2date(time.points)\n",
    "        where_good_data = np.where(model_ts < 1000.0)\n",
    "\n",
    "        if (lon >= min_lon) & (lon <= max_lon) & (lat >= min_lat) & (lat <= max_lat):\n",
    "            try:\n",
    "        #         df_surf['old_TIME'] = df_surf.TIME\n",
    "                df_surf['TIME_datetime'] = pd.to_datetime(df_surf.TIME,format='%Y-%m-%dT%H:%M:%SZ')\n",
    "                df_surf = df_surf.set_index('TIME_datetime',drop=False)\n",
    "            except:\n",
    "                pass\n",
    "            df_surf['month'] = df_surf.TIME_datetime.dt.month\n",
    "            df_surf = df_surf.groupby(pd.Grouper(freq='1D')).mean()\n",
    "\n",
    "            basedate = pd.Timestamp('1970-01-01')\n",
    "\n",
    "            model_dates = times[where_good_data]\n",
    "            model_days_since_bas = ( pd.to_datetime(model_dates)- basedate).days.values\n",
    "            model_data = model_ts[where_good_data]\n",
    "\n",
    "            obs_days_since_bas = (df_surf.index- basedate).days.values\n",
    "    #             finite_obs_data_loc = np.where(np.isfinite(df_surf.VALUES.values))\n",
    "    #             obs_days_since_bas = obs_days_since_bas[finite_obs_data_loc]\n",
    "            loc_where_obs_days_within_model_days =  np.where((obs_days_since_bas <= np.max(model_days_since_bas)) & (np.isfinite(df_surf.CPHL.values)))[0]\n",
    "            obs_days_since_bas = obs_days_since_bas[loc_where_obs_days_within_model_days]\n",
    "    #             finite_obs_data_loc = np.where(np.isfinite(df_surf.VALUES.values))\n",
    "\n",
    "            interp_function = interp1d(model_days_since_bas, model_data)\n",
    "\n",
    "            # plt.scatter(obs_days_since_bas,df_surf.VALUES.values[finite_obs_data_loc],color='r',alpha=0.5)\n",
    "    #             plt.scatter(obs_days_since_bas, interp_function(obs_days_since_bas), color='b',alpha=0.1)\n",
    "            obs_values = np.append(obs_values, df_surf.CPHL.values[loc_where_obs_days_within_model_days])\n",
    "            model_values = np.append(model_values, interp_function(obs_days_since_bas))\n",
    "            obs_latitude = np.append(obs_latitude,df_surf.LATITUDE.values[loc_where_obs_days_within_model_days])\n",
    "            obs_month = np.append(obs_month,df_surf.month.values[loc_where_obs_days_within_model_days])\n",
    "    #             plt.scatter(df_surf.VALUES.values[loc_where_obs_days_within_model_days],interp_function(obs_days_since_bas))\n",
    "\n",
    "    #     if (lon >= min_lon) & (lon <= max_lon) & (lat >= min_lat) & (lat <= max_lat):\n",
    "    #         plt.plot(times[where_good_data],model_ts[where_good_data])\n",
    "    #         try:\n",
    "    #     #         df_surf['old_TIME'] = df_surf.TIME\n",
    "    #             df_surf['TIME_datetime'] = pd.to_datetime(df_surf.TIME,format='%Y-%m-%dT%H:%M:%SZ')\n",
    "    #             df_surf['year'] = df_surf.TIME_datetime.dt.year\n",
    "    #             df_surf['month'] = df_surf.TIME_datetime.dt.month\n",
    "    #             df_surf['day'] = df_surf.TIME_datetime.dt.day\n",
    "    #             df_surf = df_surf.set_index('TIME_datetime',drop=False)\n",
    "    #         except:\n",
    "    #             pass\n",
    "\n",
    "    #         df_surf = df_surf.groupby(pd.Grouper(freq='1D')).mean()\n",
    "    #         plt.scatter(df_surf.index.values,df_surf.VALUES.values,color='r')\n",
    "    #         plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm\n",
    "import matplotlib.colors\n",
    "\n",
    "cyclic_viridis = matplotlib.colors.LinearSegmentedColormap.from_list(\n",
    "    'cyclic_viridis',\n",
    "    [(0, matplotlib.cm.viridis.colors[0]),\n",
    "     (0.25, matplotlib.cm.viridis.colors[256 // 3]),\n",
    "     (0.5, matplotlib.cm.viridis.colors[2 * 256 // 3]),\n",
    "     (0.75, matplotlib.cm.viridis.colors[-1]),\n",
    "     (1.0, matplotlib.cm.viridis.colors[0])])\n",
    "\n",
    "x,y=obs_values,model_values\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(15,6))\n",
    "# ax.scatter(x, y, c=z, s=10, edgecolor='', cmap=cm.plasma)\n",
    "# c = ax.scatter(x, y, c=obs_latitude, s=20, edgecolor='',alpha=0.25, cmap=cm.viridis)\n",
    "c = ax1.scatter(x, y, c=obs_month, s=10, edgecolor='',alpha=0.7, cmap=cyclic_viridis)\n",
    "# ax1.set_ylim([15,35])\n",
    "# ax1.set_xlim([15,35])\n",
    "ax1.set_xlabel('Observed chl')\n",
    "ax1.set_ylabel('Modelled chl')\n",
    "# ax1.plot([0,40],[0,40],'k')\n",
    "cbar1 = plt.colorbar(c,ax=ax1)\n",
    "cbar1.set_label('month of year')\n",
    "\n",
    "\n",
    "c2 = ax2.scatter(x, y, c=obs_latitude, s=10, edgecolor='',alpha=0.7, cmap=cm.viridis)\n",
    "# ax2.set_ylim([15,35])\n",
    "# ax2.set_xlim([15,35])\n",
    "ax2.set_xlabel('Observed chl')\n",
    "ax2.set_ylabel('Modelled chl')\n",
    "# ax2.plot([0,40],[0,40],'k')\n",
    "cbar2 = plt.colorbar(c2,ax=ax2)\n",
    "cbar2.set_label('latitude ($^o$N)')\n",
    "\n",
    "\n",
    "# plt.xticks(fontsize=12)\n",
    "# plt.yticks(fontsize=12)\n",
    "\n",
    "\n",
    "# plt.savefig('/Users/ph290/Documents/HalloranSync/documents/papers_in_prep/s2p3v2/figures/GBR_chl_validation_IMOS_FAIMMS.pdf')\n",
    "plt.savefig('/Users/ph290/Documents/HalloranSync/documents/papers_in_prep/s2p3v2/figures/GBR_chl_validationIMOS_FAIMMS.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_surf.CPHL.values[loc_where_obs_days_within_model_days]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_function(obs_days_since_bas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure(figsize=(5,5))\n",
    "spec = gridspec.GridSpec(ncols=1, nrows=1, figure=fig1)\n",
    "ax = fig1.add_subplot(spec[0,0])\n",
    "\n",
    "ax.plot(interp_function(obs_days_since_bas))\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(df_surf.CPHL.values[loc_where_obs_days_within_model_days],'r',alpha=0.5)\n",
    "ax2.set_ylim([0.0,0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = ccrs.PlateCarree()\n",
    "\n",
    "    \n",
    "site_codes = np.unique(df5.site_code)\n",
    "\n",
    "\n",
    "fig1 = plt.figure(figsize=(10,15))\n",
    "spec = gridspec.GridSpec(ncols=2, nrows=len(site_codes), figure=fig1)\n",
    "\n",
    "# 7,8,12,13,14,16,17,18,21,22,23,24\n",
    "for i,site_code in enumerate(site_codes):\n",
    "# site_code = site_codes[0]\n",
    "    df_surf = df5.loc[(df5.site_code == site_code)]\n",
    "    # note a a QC flag pv  2 will define that the ARGO quality control procedure was used for the dataset. QC of 1 hade some spruriously low values\n",
    "    lat = df_surf.LATITUDE.mean()\n",
    "    lon = df_surf.LONGITUDE.mean()\n",
    "    if np.isfinite(KDTree(xygood).query([lon,lat])[0]):\n",
    "        index = KDTree(xygood).query([lon,lat])[1]\n",
    "    #     xygood[index][0]\n",
    "        model_ts_cube = extract_lat_lon_cube(cube_all,xygood[index][1],xygood[index][0])\n",
    "        model_ts = model_ts_cube.data\n",
    "        time = cube_all.coord('time')\n",
    "        model_times = time.units.num2date(time.points)\n",
    "        where_good_data = np.where(model_ts < 1000.0)\n",
    "\n",
    "        if (lon >= min_lon) & (lon <= max_lon) & (lat >= min_lat) & (lat <= max_lat):\n",
    "            ax = fig1.add_subplot(spec[i,0])\n",
    "            df_surf['datetime'] = pd.to_datetime(df_surf['TIME'], format='%Y-%m-%dT%H:%M:%SZ')\n",
    "            df_surf = df_surf.set_index('datetime')\n",
    "#             df_surf = df_surf.between_time('18:00', '06:00') # Chlorophyll fluorescence in the daytime is quenched. When we derive chlorophyll from the data, we apply a flag to the derived daytime chlorophyll data. We do not currently apply a flag to daytime fluorescence data\n",
    "            df_surf = df_surf.resample('M').mean()\n",
    "\n",
    "            df_model = pd.DataFrame(model_ts,columns=['chl'])\n",
    "            df_model.index = model_times\n",
    "            df_model['chl'][df_model['chl'] > 1.0e36] = np.nan\n",
    "            df_model = df_model.resample('M').mean()\n",
    "            ax2 = ax.twinx()\n",
    "            y=df_model['chl']\n",
    "            ax2.plot(df_model.index,(y - np.min(y))/(np.std(y)),'r',label='S2P3R v2.0')\n",
    "            ax2.set_ylabel('normalised surface\\nmodel chlorophyll').set_color('r')\n",
    "            ax2.set_ylim(0.0,5.0)\n",
    "        \n",
    "            loc = np.logical_not(np.isfinite(df_surf.CPHL.values))\n",
    "            df_surf.CPHL.values[loc] = np.nan\n",
    "#             df_surf.index.values[loc] = np.nan\n",
    "            y = df_surf.CPHL.values\n",
    "            ax.plot(df_surf.index.values,(y - np.nanmin(y))/(np.nanstd(y)),color='k',label='observed')\n",
    "            ax.set_ylim(0.0,5.0)\n",
    "            ax.set_ylabel('normalised mooring chlorophyll\\nwithin upper 10m').set_color('k')\n",
    "            \n",
    "            ax.set_xlim(datetime.datetime(2008, 1, 1, 0, 0),datetime.datetime(2020, 1, 1, 0, 0))\n",
    "\n",
    "            \n",
    "            # map\n",
    "\n",
    "            ax3 = fig1.add_subplot(spec[i,1],projection=projection)\n",
    "\n",
    "            ax3.set_extent([140, 155, -35, -10], ccrs.PlateCarree())\n",
    "\n",
    "            ax3.add_feature(cfeature.LAND)\n",
    "            ax3.coastlines('10m')\n",
    "\n",
    "            lon_model = model_ts_cube.coord('longitude')\n",
    "            lat_model = model_ts_cube.coord('latitude')\n",
    "            ax3.scatter(lon, lat, color='b',marker='o',s=100, transform=projection,alpha=0.5)\n",
    "            ax3.scatter(lon_model.points[0], lat_model.points[0], color='r',marker='o',s=100, transform=projection,alpha=0.5)\n",
    "\n",
    "    #         ax.set_title(file.split('/')[-1].split('.')[0])\n",
    "            if i == len(site_codes)-1:\n",
    "                ax.set_xlabel('year')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Users/ph290/Documents/HalloranSync/documents/papers_in_prep/s2p3v2/figures/GBR_chl_validationIMOS_FAIMMS_timeseries.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Satilite comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_for_basic_comparison = 2010\n",
    "min_year_for_comparison = 1997\n",
    "max_year_for_comparison = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012\n",
      " 2013 2014 2015 2016]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ph290/miniconda2/lib/python2.7/site-packages/iris/coords.py:1017: UserWarning: Collapsing a non-contiguous coordinate. Metadata may not be fully descriptive for u'time'.\n",
      "  warnings.warn(msg.format(self.name()))\n"
     ]
    }
   ],
   "source": [
    "# obs_cube = iris.load_cube('/Users/ph290/Downloads/global_tropics/coraltemp_v1.0_19890101.nc','sea_surface_temperature')[0]\n",
    "# obs_cube = iris.load_cube('/Users/ph290/Downloads/global_tropics/coraltemp_v1.0_1989.nc','sea_surface_temperature')\n",
    "\n",
    "# getting satilite data: /data/BatCaveNAS/ph290/ocean_color_cci$ vim download_cci_chl_v4.py\n",
    "\n",
    "obs_cube_all = iris.load_cube('/Users/ph290/Downloads/GBR/ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-all_years-fv4.2_gbr.nc')\n",
    "\n",
    "# copied from groupserv:/data/BatCaveNAS/ph290/obs/\n",
    "# obs_cube = iris.load_cube('/Users/ph290/Downloads/global_tropics/coraltemp_v1.0_2008_all_tm.nc','sea_surface_temperature')\n",
    "\n",
    "# obs_cube_all = select_season(obs_cube_all,season_for_analysis)\n",
    "\n",
    "obs_cube_all_monthly = obs_cube_all.copy()\n",
    "\n",
    "\n",
    "try:\n",
    "    iris.coord_categorisation.add_year(obs_cube_all, 'time', name='year')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "obs_cube_all = obs_cube_all.aggregated_by('year', iris.analysis.MEAN)\n",
    "\n",
    "print obs_cube_all.coord('year').points\n",
    "\n",
    "\n",
    "obs_cube = obs_cube_all[np.where((obs_cube_all.coord('year').points >= min_year_for_comparison) & (obs_cube_all.coord('year').points <= max_year_for_comparison))]\n",
    "obs_cube_ym = obs_cube.copy()\n",
    "obs_cube = obs_cube.collapsed('time',iris.analysis.MEAN)\n",
    "# obs_cube = obs_cube_all[np.where(obs_cube_all.coord('year').points == year_for_basic_comparison)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/ph290/Downloads/era5_GBR/era5_GBR_surfacechlorophyll.nc'\n",
    "# era5_GBR_surfacechlorophyll.nc\n",
    "\n",
    "cube_all = iris.load_cube(file)\n",
    "\n",
    "cube_all_monthly = cube_all.copy()\n",
    "\n",
    "# cube_all = select_season(cube_all,season_for_analysis)\n",
    "\n",
    "\n",
    "try:\n",
    "    iris.coord_categorisation.add_year(cube_all, 'time', name='year')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "cube_all = cube_all.aggregated_by('year', iris.analysis.MEAN)\n",
    "\n",
    "\n",
    "# cube_all.coord('longitude').points = cube_all.coord('longitude').points+180\n",
    "# cube_all.data = np.ma.masked_array(cube_all.data)\n",
    "# cube_all.data.fill_value = 9.96920997e+36\n",
    "cube_all.data = np.ma.masked_where(cube_all.data == 9.96920997e+36, cube_all.data)\n",
    "# iris.coord_categorisation.add_year(cube_all, 'time', name='year')\n",
    "cube = cube_all[np.where((cube_all.coord('year').points >= min_year_for_comparison) & (cube_all.coord('year').points <= max_year_for_comparison))]\n",
    "cube_ym = cube.copy()\n",
    "cube = cube.collapsed('time',iris.analysis.MEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_50m = cfeature.NaturalEarthFeature('physical', 'land', '50m',\n",
    "                                        edgecolor='face',\n",
    "                                        facecolor=cfeature.COLORS['land'])\n",
    "\n",
    "land_10m = cfeature.NaturalEarthFeature('physical', 'land', '10m',\n",
    "                                        edgecolor='face',\n",
    "                                        facecolor=cfeature.COLORS['land'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-9c4676839932>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel_data_masked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_where\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mlon_west\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m140\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 14}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "\n",
    "model_data_masked = np.ma.masked_where(np.logical_not(np.isfinite(model_data)),model_data)\n",
    "\n",
    "lon_west = 140\n",
    "lon_east = 155\n",
    "lat_south = -35\n",
    "lat_north = -10\n",
    "\n",
    "my_vmax = 5.0\n",
    "\n",
    "c_model = extract_region(cube,lon_west,lon_east,lat_south,lat_north)\n",
    "# c_model.coord('longitude').points = c_model.coord('longitude').points + 180\n",
    "\n",
    "c_cci_region = extract_region(obs_cube,lon_west,lon_east,lat_south,lat_north)\n",
    "\n",
    "c_model.coord('latitude').coord_system = c_cci_region.coord('latitude').coord_system\n",
    "c_model.coord('longitude').coord_system =c_cci_region.coord('longitude').coord_system\n",
    "\n",
    "c_cci_region_regridded = c_cci_region.regrid(c_model, iris.analysis.Linear())\n",
    "# obs_cube_all_region.data.mask = obs_cube_all_region_regridded.data.mask\n",
    "\n",
    "# model_data = iris.analysis.maths.log(c_model/10.0).data\n",
    "model_data = (c_model/10.0).data\n",
    "lat_model = c_model.coord('latitude').points\n",
    "lon_model = c_model.coord('longitude').points\n",
    "\n",
    "\n",
    "# cci_data = iris.analysis.maths.log(c_cci_region_regridded).data\n",
    "cci_data = c_cci_region_regridded.data\n",
    "lat_cci = c_cci_region_regridded.coord('latitude').points\n",
    "lon_cci = c_cci_region_regridded.coord('longitude').points\n",
    "cci_data.mask = model_data_masked.mask\n",
    "\n",
    "bathy_file = '/Users/ph290/Downloads/ETOPO1_Bed_g_gmt4_low_res.nc'\n",
    "bathy_cube = iris.load_cube(bathy_file)\n",
    "bathy_cube.data = np.ma.masked_where(bathy_cube.data >= 0.0,bathy_cube.data)\n",
    "bathy_cube.data = np.ma.masked_where(bathy_cube.data < -100.0,bathy_cube.data)\n",
    "\n",
    "\n",
    "\n",
    "bathy_cube = extract_region(bathy_cube,lon_west,lon_east,lat_south,lat_north)\n",
    "\n",
    "bathy_data = bathy_cube.data\n",
    "lat_bathy = bathy_cube.coord('latitude').points\n",
    "lon_bathy = bathy_cube.coord('longitude').points\n",
    "\n",
    "lon_west2 = lon_west\n",
    "lon_east2 = lon_east\n",
    "lat_south2 = lat_south\n",
    "lat_north2 = lat_north\n",
    "\n",
    "plt.close('all')\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "ax1 = fig.add_subplot(1, 3, 1, projection=ccrs.PlateCarree())\n",
    "ax2 = fig.add_subplot(1, 3, 2, projection=ccrs.PlateCarree())\n",
    "ax3 = fig.add_subplot(1, 3, 3, projection=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "#####################\n",
    "\n",
    "ax1.set_extent((lon_west2, lon_east2, lat_south2, lat_north2), crs=ccrs.PlateCarree())\n",
    "\n",
    "ax1.contour(lon_bathy, lat_bathy,bathy_data,5,colors = 'k')\n",
    "\n",
    "# p1 = ax1.pcolormesh(lon_cci, lat_model,cci_data,\n",
    "#                 transform=ccrs.PlateCarree(),\n",
    "#                 vmin=0.0,vmax=my_vmax,\n",
    "#                 cmap='viridis')\n",
    "\n",
    "p1 = ax1.pcolormesh(lon_cci, lat_model,cci_data,\n",
    "                transform=ccrs.PlateCarree(),\n",
    "                vmin=0.0,vmax=my_vmax,\n",
    "                cmap='viridis')\n",
    "\n",
    "\n",
    "# plt.colorbar(p1)\n",
    "cbar1 = fig.colorbar(p1,orientation='horizontal', ax=ax1)\n",
    "# cbar1 = plt.colorbar(p1,orientation='horizontal')\n",
    "# cbar1.set_label('log(mg $^{m-3}$)')\n",
    "cbar1.set_label('mg $^{m-3}$')\n",
    "\n",
    "ax1.add_feature(land_10m, edgecolor='k')\n",
    "\n",
    "ax1.title.set_text('satilite Chl-a\\n1997-2017 mean')\n",
    "\n",
    "#####################\n",
    "\n",
    "ax2.set_extent((lon_west2, lon_east2, lat_south2, lat_north2), crs=ccrs.PlateCarree())\n",
    "\n",
    "ax2.contour(lon_bathy, lat_bathy,bathy_data,5,colors = 'k')\n",
    "\n",
    "p2 = ax2.pcolormesh(lon_cci, lat_model,model_data,\n",
    "                transform=ccrs.PlateCarree(),\n",
    "                vmin=0.0,vmax=my_vmax,\n",
    "                cmap='viridis')\n",
    "# plt.colorbar(p1)\n",
    "cbar2 = fig.colorbar(p2,orientation='horizontal', ax=ax2)\n",
    "# cbar1 = plt.colorbar(p1,orientation='horizontal')\n",
    "# cbar2.set_label('log(mg $^{m-3}$)')\n",
    "cbar2.set_label('mg $^{m-3}$')\n",
    "\n",
    "ax2.add_feature(land_10m, edgecolor='k')\n",
    "\n",
    "ax2.title.set_text('S2P3R v2.0 Model \\n1997-2017 mean')\n",
    "\n",
    "\n",
    "#####################\n",
    "\n",
    "# ax3 = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax3.set_extent((lon_west2, lon_east2, lat_south2, lat_north2), crs=ccrs.PlateCarree())\n",
    "\n",
    "# ax3 = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "ax3.contour(lon_bathy, lat_bathy,bathy_data,5,colors = 'k')\n",
    "\n",
    "p3 = ax3.pcolormesh(lon_cci, lat_model,model_data - cci_data,\n",
    "                transform=ccrs.PlateCarree(),vmin=-2,vmax=2,\n",
    "                cmap='bwr')\n",
    "# plt.colorbar(p3)\n",
    "cbar3 = fig.colorbar(p3,orientation='horizontal', ax=ax3)\n",
    "# cbar = plt.colorbar(p3,orientation='horizontal')\n",
    "# cbar1.set_label('log(mg $^{m-3}$)')\n",
    "cbar3.set_label('mg $^{m-3}$')\n",
    "\n",
    "ax3.add_feature(land_10m, edgecolor='k')\n",
    "\n",
    "ax3.title.set_text('S2P3Rv2.0 Model Chl-a\\nminus satilite Chl-a\\n1997-2017 mean')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "#################\n",
    "\n",
    "plt.savefig('/Users/ph290/Documents/HalloranSync/documents/papers_in_prep/s2p3v2/figures/GBR_chla_validation_map.png',dpi=600)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global chl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2007]\n"
     ]
    }
   ],
   "source": [
    "# obs_cube = iris.load_cube('/Users/ph290/Downloads/global_tropics/coraltemp_v1.0_19890101.nc','sea_surface_temperature')[0]\n",
    "# obs_cube = iris.load_cube('/Users/ph290/Downloads/global_tropics/coraltemp_v1.0_1989.nc','sea_surface_temperature')\n",
    "\n",
    "# getting satilite data: /data/BatCaveNAS/ph290/ocean_color_cci$ vim download_cci_chl_v4.py\n",
    "\n",
    "obs_cube_all = iris.load_cube('/Users/ph290/Downloads/ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-all_years-fv4.2_timemean.nc')\n",
    "\n",
    "# copied from groupserv:/data/BatCaveNAS/ph290/obs/\n",
    "# obs_cube = iris.load_cube('/Users/ph290/Downloads/global_tropics/coraltemp_v1.0_2008_all_tm.nc','sea_surface_temperature')\n",
    "\n",
    "# obs_cube_all = select_season(obs_cube_all,season_for_analysis)\n",
    "\n",
    "obs_cube_all_monthly = obs_cube_all.copy()\n",
    "\n",
    "\n",
    "try:\n",
    "    iris.coord_categorisation.add_year(obs_cube_all, 'time', name='year')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "obs_cube_all = obs_cube_all.aggregated_by('year', iris.analysis.MEAN)\n",
    "\n",
    "print obs_cube_all.coord('year').points\n",
    "\n",
    "\n",
    "obs_cube = obs_cube_all[np.where((obs_cube_all.coord('year').points >= min_year_for_comparison) & (obs_cube_all.coord('year').points <= max_year_for_comparison))]\n",
    "obs_cube_ym = obs_cube.copy()\n",
    "obs_cube = obs_cube.collapsed('time',iris.analysis.MEAN)\n",
    "# obs_cube = obs_cube_all[np.where(obs_cube_all.coord('year').points == year_for_basic_comparison)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/ph290/Downloads/ERA5_global_surfacechlorophyll_timemean.nc'\n",
    "# era5_GBR_surfacechlorophyll.nc\n",
    "\n",
    "cube_all = iris.load_cube(file)\n",
    "\n",
    "cube_all_monthly = cube_all.copy()\n",
    "\n",
    "# cube_all = select_season(cube_all,season_for_analysis)\n",
    "\n",
    "\n",
    "try:\n",
    "    iris.coord_categorisation.add_year(cube_all, 'time', name='year')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "cube_all = cube_all.aggregated_by('year', iris.analysis.MEAN)\n",
    "\n",
    "\n",
    "# cube_all.coord('longitude').points = cube_all.coord('longitude').points+180\n",
    "# cube_all.data = np.ma.masked_array(cube_all.data)\n",
    "# cube_all.data.fill_value = 9.96920997e+36\n",
    "cube_all.data = np.ma.masked_where(cube_all.data == 9.96920997e+36, cube_all.data)\n",
    "# iris.coord_categorisation.add_year(cube_all, 'time', name='year')\n",
    "cube = cube_all[np.where((cube_all.coord('year').points >= min_year_for_comparison) & (cube_all.coord('year').points <= max_year_for_comparison))]\n",
    "cube_ym = cube.copy()\n",
    "cube = cube.collapsed('time',iris.analysis.MEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-d5125ebf4160>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel_data_masked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_where\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mlon_west\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_data' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 12}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "\n",
    "model_data_masked = np.ma.masked_where(np.logical_not(np.isfinite(model_data)),model_data)\n",
    "\n",
    "lon_west = -180\n",
    "lon_east = 180\n",
    "lat_south = -65\n",
    "lat_north = 65\n",
    "\n",
    "my_vmax = 5.0\n",
    "\n",
    "c_model = extract_region(cube,lon_west,lon_east,lat_south,lat_north)\n",
    "# c_model.coord('longitude').points = c_model.coord('longitude').points + 180\n",
    "\n",
    "c_cci_region = extract_region(obs_cube,lon_west,lon_east,lat_south,lat_north)\n",
    "\n",
    "c_model.coord('latitude').coord_system = c_cci_region.coord('latitude').coord_system\n",
    "c_model.coord('longitude').coord_system =c_cci_region.coord('longitude').coord_system\n",
    "\n",
    "c_cci_region_regridded = c_cci_region.regrid(c_model, iris.analysis.Linear())\n",
    "# obs_cube_all_region.data.mask = obs_cube_all_region_regridded.data.mask\n",
    "\n",
    "# model_data = iris.analysis.maths.log(c_model/10.0).data\n",
    "model_data = (c_model/10.0).data\n",
    "lat_model = c_model.coord('latitude').points\n",
    "lon_model = c_model.coord('longitude').points\n",
    "\n",
    "\n",
    "# cci_data = iris.analysis.maths.log(c_cci_region_regridded).data\n",
    "cci_data = c_cci_region_regridded.data\n",
    "lat_cci = c_cci_region_regridded.coord('latitude').points\n",
    "lon_cci = c_cci_region_regridded.coord('longitude').points\n",
    "cci_data.mask = c_model.data.mask\n",
    "\n",
    "bathy_file = '/Users/ph290/Downloads/ETOPO1_Bed_g_gmt4_low_res.nc'\n",
    "bathy_cube = iris.load_cube(bathy_file)\n",
    "bathy_cube.data = np.ma.masked_where(bathy_cube.data >= 0.0,bathy_cube.data)\n",
    "bathy_cube.data = np.ma.masked_where(bathy_cube.data < -100.0,bathy_cube.data)\n",
    "\n",
    "\n",
    "\n",
    "bathy_cube = extract_region(bathy_cube,lon_west,lon_east,lat_south,lat_north)\n",
    "\n",
    "bathy_data = bathy_cube.data\n",
    "lat_bathy = bathy_cube.coord('latitude').points\n",
    "lon_bathy = bathy_cube.coord('longitude').points\n",
    "\n",
    "lon_west2 = lon_west\n",
    "lon_east2 = lon_east\n",
    "lat_south2 = lat_south\n",
    "lat_north2 = lat_north\n",
    "\n",
    "plt.close('all')\n",
    "# fig = plt.figure() #figsize=(12, 20)\n",
    "# ax1 = fig.add_subplot(1, 1, 3, projection=ccrs.PlateCarree())\n",
    "# ax2 = fig.add_subplot(2, 2, 3, projection=ccrs.PlateCarree())\n",
    "# ax3 = fig.add_subplot(3, 3, 3, projection=ccrs.PlateCarree())\n",
    "\n",
    "fig = plt.figure(figsize=(12, 20))\n",
    "spec2 = gridspec.GridSpec(ncols=1, nrows=3, figure=fig)\n",
    "ax1 = fig.add_subplot(spec2[0, 0], projection=ccrs.PlateCarree())\n",
    "ax2 = fig.add_subplot(spec2[1, 0], projection=ccrs.PlateCarree())\n",
    "ax3 = fig.add_subplot(spec2[2, 0], projection=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "\n",
    "#####################\n",
    "\n",
    "ax1.set_extent((lon_west2, lon_east2, lat_south2, lat_north2), crs=ccrs.PlateCarree())\n",
    "\n",
    "# ax1.contour(lon_bathy, lat_bathy,bathy_data,5,colors = 'k')\n",
    "\n",
    "# p1 = ax1.pcolormesh(lon_cci, lat_model,cci_data,\n",
    "#                 transform=ccrs.PlateCarree(),\n",
    "#                 vmin=0.0,vmax=my_vmax,\n",
    "#                 cmap='viridis')\n",
    "\n",
    "p1 = ax1.pcolormesh(lon_cci, lat_model,cci_data,\n",
    "                transform=ccrs.PlateCarree(),\n",
    "                vmin=0.0,vmax=my_vmax,\n",
    "                cmap='viridis')\n",
    "\n",
    "\n",
    "# plt.colorbar(p1)\n",
    "cbar1 = fig.colorbar(p1,orientation='horizontal', ax=ax1)\n",
    "# cbar1 = plt.colorbar(p1,orientation='horizontal')\n",
    "# cbar1.set_label('log(mg $^{m-3}$)')\n",
    "cbar1.set_label('mg $^{m-3}$')\n",
    "\n",
    "# ax1.add_feature(land_10m, edgecolor='k')\n",
    "\n",
    "ax1.title.set_text('satilite Chl-a\\n1997-2017 mean')\n",
    "\n",
    "#####################\n",
    "\n",
    "ax2.set_extent((lon_west2, lon_east2, lat_south2, lat_north2), crs=ccrs.PlateCarree())\n",
    "\n",
    "# ax2.contour(lon_bathy, lat_bathy,bathy_data,5,colors = 'k')\n",
    "\n",
    "p2 = ax2.pcolormesh(lon_cci, lat_model,model_data,\n",
    "                transform=ccrs.PlateCarree(),\n",
    "                vmin=0.0,vmax=my_vmax,\n",
    "                cmap='viridis')\n",
    "# plt.colorbar(p1)\n",
    "cbar2 = fig.colorbar(p2,orientation='horizontal', ax=ax2)\n",
    "# cbar1 = plt.colorbar(p1,orientation='horizontal')\n",
    "# cbar2.set_label('log(mg $^{m-3}$)')\n",
    "cbar2.set_label('mg $^{m-3}$')\n",
    "\n",
    "# ax2.add_feature(land_10m, edgecolor='k')\n",
    "\n",
    "ax2.title.set_text('S2P3R v2.0 Model \\n1997-2017 mean')\n",
    "\n",
    "\n",
    "#####################\n",
    "\n",
    "# ax3 = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax3.set_extent((lon_west2, lon_east2, lat_south2, lat_north2), crs=ccrs.PlateCarree())\n",
    "\n",
    "# ax3 = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "# ax3.contour(lon_bathy, lat_bathy,bathy_data,5,colors = 'k')\n",
    "\n",
    "p3 = ax3.pcolormesh(lon_cci, lat_model,model_data - cci_data,\n",
    "                transform=ccrs.PlateCarree(),vmin=-2,vmax=2,\n",
    "                cmap='bwr')\n",
    "# plt.colorbar(p3)\n",
    "cbar3 = fig.colorbar(p3,orientation='horizontal', ax=ax3)\n",
    "# cbar = plt.colorbar(p3,orientation='horizontal')\n",
    "# cbar1.set_label('log(mg $^{m-3}$)')\n",
    "cbar3.set_label('mg $^{m-3}$')\n",
    "\n",
    "# ax3.add_feature(land_10m, edgecolor='k')\n",
    "\n",
    "ax3.title.set_text('S2P3Rv2.0 Model Chl-a\\nminus satilite Chl-a\\n1997-2017 mean')\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "#################\n",
    "\n",
    "plt.savefig('/Users/ph290/Documents/HalloranSync/documents/papers_in_prep/s2p3v2/figures/global_chla_validation_map.png',dpi=600)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## log scale plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matplotlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-091a9d3ef711>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         'size'   : 12}\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'font'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matplotlib' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 12}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "\n",
    "model_data_masked = np.ma.masked_where(np.logical_not(np.isfinite(model_data)),model_data)\n",
    "\n",
    "lon_west = -180\n",
    "lon_east = 180\n",
    "lat_south = -65\n",
    "lat_north = 65\n",
    "\n",
    "my_vmax = 5.0\n",
    "\n",
    "c_model = extract_region(cube,lon_west,lon_east,lat_south,lat_north)\n",
    "# c_model.coord('longitude').points = c_model.coord('longitude').points + 180\n",
    "\n",
    "c_cci_region = extract_region(obs_cube,lon_west,lon_east,lat_south,lat_north)\n",
    "\n",
    "c_model.coord('latitude').coord_system = c_cci_region.coord('latitude').coord_system\n",
    "c_model.coord('longitude').coord_system =c_cci_region.coord('longitude').coord_system\n",
    "\n",
    "c_cci_region_regridded = c_cci_region.regrid(c_model, iris.analysis.Linear())\n",
    "# obs_cube_all_region.data.mask = obs_cube_all_region_regridded.data.mask\n",
    "\n",
    "# model_data = iris.analysis.maths.log(c_model/10.0).data\n",
    "model_data = (c_model/10.0).data\n",
    "lat_model = c_model.coord('latitude').points\n",
    "lon_model = c_model.coord('longitude').points\n",
    "\n",
    "\n",
    "# cci_data = iris.analysis.maths.log(c_cci_region_regridded).data\n",
    "cci_data = c_cci_region_regridded.data\n",
    "lat_cci = c_cci_region_regridded.coord('latitude').points\n",
    "lon_cci = c_cci_region_regridded.coord('longitude').points\n",
    "cci_data.mask = c_model.data.mask\n",
    "\n",
    "bathy_file = '/Users/ph290/Downloads/ETOPO1_Bed_g_gmt4_low_res.nc'\n",
    "bathy_cube = iris.load_cube(bathy_file)\n",
    "bathy_cube.data = np.ma.masked_where(bathy_cube.data >= 0.0,bathy_cube.data)\n",
    "bathy_cube.data = np.ma.masked_where(bathy_cube.data < -100.0,bathy_cube.data)\n",
    "\n",
    "\n",
    "\n",
    "bathy_cube = extract_region(bathy_cube,lon_west,lon_east,lat_south,lat_north)\n",
    "\n",
    "bathy_data = bathy_cube.data\n",
    "lat_bathy = bathy_cube.coord('latitude').points\n",
    "lon_bathy = bathy_cube.coord('longitude').points\n",
    "\n",
    "lon_west2 = lon_west\n",
    "lon_east2 = lon_east\n",
    "lat_south2 = lat_south\n",
    "lat_north2 = lat_north\n",
    "\n",
    "plt.close('all')\n",
    "# fig = plt.figure() #figsize=(12, 20)\n",
    "# ax1 = fig.add_subplot(1, 1, 3, projection=ccrs.PlateCarree())\n",
    "# ax2 = fig.add_subplot(2, 2, 3, projection=ccrs.PlateCarree())\n",
    "# ax3 = fig.add_subplot(3, 3, 3, projection=ccrs.PlateCarree())\n",
    "\n",
    "fig = plt.figure(figsize=(12, 20))\n",
    "spec2 = gridspec.GridSpec(ncols=1, nrows=3, figure=fig)\n",
    "ax1 = fig.add_subplot(spec2[0, 0], projection=ccrs.PlateCarree())\n",
    "ax2 = fig.add_subplot(spec2[1, 0], projection=ccrs.PlateCarree())\n",
    "ax3 = fig.add_subplot(spec2[2, 0], projection=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "\n",
    "#####################\n",
    "\n",
    "ax1.set_extent((lon_west2, lon_east2, lat_south2, lat_north2), crs=ccrs.PlateCarree())\n",
    "\n",
    "# ax1.contour(lon_bathy, lat_bathy,bathy_data,5,colors = 'k')\n",
    "\n",
    "# p1 = ax1.pcolormesh(lon_cci, lat_model,cci_data,\n",
    "#                 transform=ccrs.PlateCarree(),\n",
    "#                 vmin=0.0,vmax=my_vmax,\n",
    "#                 cmap='viridis')\n",
    "\n",
    "p1 = ax1.pcolormesh(lon_cci, lat_model,np.log(cci_data),\n",
    "                transform=ccrs.PlateCarree(),\n",
    "                vmin=0.0,vmax=my_vmax,\n",
    "                cmap='viridis')\n",
    "\n",
    "\n",
    "# plt.colorbar(p1)\n",
    "cbar1 = fig.colorbar(p1,orientation='horizontal', ax=ax1)\n",
    "# cbar1 = plt.colorbar(p1,orientation='horizontal')\n",
    "# cbar1.set_label('log(mg $^{m-3}$)')\n",
    "cbar1.set_label('mg $^{m-3}$')\n",
    "\n",
    "# ax1.add_feature(land_10m, edgecolor='k')\n",
    "\n",
    "ax1.title.set_text('satilite Chl-a\\n1997-2017 mean')\n",
    "\n",
    "#####################\n",
    "\n",
    "ax2.set_extent((lon_west2, lon_east2, lat_south2, lat_north2), crs=ccrs.PlateCarree())\n",
    "\n",
    "# ax2.contour(lon_bathy, lat_bathy,bathy_data,5,colors = 'k')\n",
    "\n",
    "p2 = ax2.pcolormesh(lon_cci, lat_model,np.log(model_data),\n",
    "                transform=ccrs.PlateCarree(),\n",
    "                vmin=0.0,vmax=my_vmax,\n",
    "                cmap='viridis')\n",
    "# plt.colorbar(p1)\n",
    "cbar2 = fig.colorbar(p2,orientation='horizontal', ax=ax2)\n",
    "# cbar1 = plt.colorbar(p1,orientation='horizontal')\n",
    "# cbar2.set_label('log(mg $^{m-3}$)')\n",
    "cbar2.set_label('mg $^{m-3}$')\n",
    "\n",
    "# ax2.add_feature(land_10m, edgecolor='k')\n",
    "\n",
    "ax2.title.set_text('S2P3R v2.0 Model \\n1997-2017 mean')\n",
    "\n",
    "\n",
    "#####################\n",
    "\n",
    "# ax3 = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax3.set_extent((lon_west2, lon_east2, lat_south2, lat_north2), crs=ccrs.PlateCarree())\n",
    "\n",
    "# ax3 = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "# ax3.contour(lon_bathy, lat_bathy,bathy_data,5,colors = 'k')\n",
    "\n",
    "p3 = ax3.pcolormesh(lon_cci, lat_model,np.log(model_data) - np.log(cci_data),\n",
    "                transform=ccrs.PlateCarree(),vmin=-2,vmax=2,\n",
    "                cmap='bwr')\n",
    "# plt.colorbar(p3)\n",
    "cbar3 = fig.colorbar(p3,orientation='horizontal', ax=ax3)\n",
    "# cbar = plt.colorbar(p3,orientation='horizontal')\n",
    "# cbar1.set_label('log(mg $^{m-3}$)')\n",
    "cbar3.set_label('mg $^{m-3}$')\n",
    "\n",
    "# ax3.add_feature(land_10m, edgecolor='k')\n",
    "\n",
    "ax3.title.set_text('S2P3Rv2.0 Model Chl-a\\nminus satilite Chl-a\\n1997-2017 mean')\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "#################\n",
    "\n",
    "plt.savefig('/Users/ph290/Documents/HalloranSync/documents/papers_in_prep/s2p3v2/figures/global_chla_validation_map2.png',dpi=600)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
